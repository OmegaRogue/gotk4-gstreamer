// Code generated by girgen. DO NOT EDIT.

package gstbase

import (
	"runtime"
	"unsafe"

	"github.com/OmegaRogue/gotk4-gstreamer/pkg/gst"
	"github.com/diamondburned/gotk4/pkg/core/gextras"
	coreglib "github.com/diamondburned/gotk4/pkg/core/glib"
)

// #include <stdlib.h>
// #include <glib-object.h>
// #include <gst/base/base.h>
// extern void _gotk4_gstbase1_Aggregator_ConnectSamplesSelected(gpointer, GstSegment*, guint64, guint64, guint64, GstStructure*, guintptr);
// extern void _gotk4_gstbase1_AggregatorPad_ConnectBufferConsumed(gpointer, GstBuffer*, guintptr);
// extern gboolean _gotk4_gstbase1_AggregatorPadClass_skip_buffer(GstAggregatorPad*, GstAggregator*, GstBuffer*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_stop(GstAggregator*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_start(GstAggregator*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_src_query(GstAggregator*, GstQuery*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_src_event(GstAggregator*, GstEvent*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_src_activate(GstAggregator*, GstPadMode, gboolean);
// extern gboolean _gotk4_gstbase1_AggregatorClass_sink_query_pre_queue(GstAggregator*, GstAggregatorPad*, GstQuery*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_sink_query(GstAggregator*, GstAggregatorPad*, GstQuery*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_sink_event(GstAggregator*, GstAggregatorPad*, GstEvent*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_propose_allocation(GstAggregator*, GstAggregatorPad*, GstQuery*, GstQuery*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_negotiated_src_caps(GstAggregator*, GstCaps*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_negotiate(GstAggregator*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_decide_allocation(GstAggregator*, GstQuery*);
// extern GstSample* _gotk4_gstbase1_AggregatorClass_peek_next_sample(GstAggregator*, GstAggregatorPad*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorPadClass_flush(GstAggregatorPad*, GstAggregator*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_update_src_caps(GstAggregator*, GstCaps*, GstCaps**);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_sink_event_pre_queue(GstAggregator*, GstAggregatorPad*, GstEvent*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_flush(GstAggregator*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_finish_buffer_list(GstAggregator*, GstBufferList*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_finish_buffer(GstAggregator*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_aggregate(GstAggregator*, gboolean);
// extern GstClockTime _gotk4_gstbase1_AggregatorClass_get_next_time(GstAggregator*);
// extern GstCaps* _gotk4_gstbase1_AggregatorClass_fixate_src_caps(GstAggregator*, GstCaps*);
// extern GstBuffer* _gotk4_gstbase1_AggregatorClass_clip(GstAggregator*, GstAggregatorPad*, GstBuffer*);
// GstBuffer* _gotk4_gstbase1_Aggregator_virtual_clip(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstBuffer* arg2) {
//   return ((GstBuffer* (*)(GstAggregator*, GstAggregatorPad*, GstBuffer*))(fnptr))(arg0, arg1, arg2);
// };
// GstCaps* _gotk4_gstbase1_Aggregator_virtual_fixate_src_caps(void* fnptr, GstAggregator* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstAggregator*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstClockTime _gotk4_gstbase1_Aggregator_virtual_get_next_time(void* fnptr, GstAggregator* arg0) {
//   return ((GstClockTime (*)(GstAggregator*))(fnptr))(arg0);
// };
// GstFlowReturn _gotk4_gstbase1_AggregatorPad_virtual_flush(void* fnptr, GstAggregatorPad* arg0, GstAggregator* arg1) {
//   return ((GstFlowReturn (*)(GstAggregatorPad*, GstAggregator*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_aggregate(void* fnptr, GstAggregator* arg0, gboolean arg1) {
//   return ((GstFlowReturn (*)(GstAggregator*, gboolean))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_finish_buffer(void* fnptr, GstAggregator* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstAggregator*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_finish_buffer_list(void* fnptr, GstAggregator* arg0, GstBufferList* arg1) {
//   return ((GstFlowReturn (*)(GstAggregator*, GstBufferList*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_flush(void* fnptr, GstAggregator* arg0) {
//   return ((GstFlowReturn (*)(GstAggregator*))(fnptr))(arg0);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_sink_event_pre_queue(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstEvent* arg2) {
//   return ((GstFlowReturn (*)(GstAggregator*, GstAggregatorPad*, GstEvent*))(fnptr))(arg0, arg1, arg2);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_update_src_caps(void* fnptr, GstAggregator* arg0, GstCaps* arg1, GstCaps** arg2) {
//   return ((GstFlowReturn (*)(GstAggregator*, GstCaps*, GstCaps**))(fnptr))(arg0, arg1, arg2);
// };
// GstSample* _gotk4_gstbase1_Aggregator_virtual_peek_next_sample(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1) {
//   return ((GstSample* (*)(GstAggregator*, GstAggregatorPad*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_AggregatorPad_virtual_skip_buffer(void* fnptr, GstAggregatorPad* arg0, GstAggregator* arg1, GstBuffer* arg2) {
//   return ((gboolean (*)(GstAggregatorPad*, GstAggregator*, GstBuffer*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_decide_allocation(void* fnptr, GstAggregator* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAggregator*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_negotiate(void* fnptr, GstAggregator* arg0) {
//   return ((gboolean (*)(GstAggregator*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_negotiated_src_caps(void* fnptr, GstAggregator* arg0, GstCaps* arg1) {
//   return ((gboolean (*)(GstAggregator*, GstCaps*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_propose_allocation(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstQuery* arg2, GstQuery* arg3) {
//   return ((gboolean (*)(GstAggregator*, GstAggregatorPad*, GstQuery*, GstQuery*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_sink_event(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstEvent* arg2) {
//   return ((gboolean (*)(GstAggregator*, GstAggregatorPad*, GstEvent*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_sink_query(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstQuery* arg2) {
//   return ((gboolean (*)(GstAggregator*, GstAggregatorPad*, GstQuery*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_sink_query_pre_queue(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstQuery* arg2) {
//   return ((gboolean (*)(GstAggregator*, GstAggregatorPad*, GstQuery*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_src_activate(void* fnptr, GstAggregator* arg0, GstPadMode arg1, gboolean arg2) {
//   return ((gboolean (*)(GstAggregator*, GstPadMode, gboolean))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_src_event(void* fnptr, GstAggregator* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstAggregator*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_src_query(void* fnptr, GstAggregator* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAggregator*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_start(void* fnptr, GstAggregator* arg0) {
//   return ((gboolean (*)(GstAggregator*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_stop(void* fnptr, GstAggregator* arg0) {
//   return ((gboolean (*)(GstAggregator*))(fnptr))(arg0);
// };
import "C"

// GType values.
var (
	GTypeAggregator    = coreglib.Type(C.gst_aggregator_get_type())
	GTypeAggregatorPad = coreglib.Type(C.gst_aggregator_pad_get_type())
)

func init() {
	coreglib.RegisterGValueMarshalers([]coreglib.TypeMarshaler{
		coreglib.TypeMarshaler{T: GTypeAggregator, F: marshalAggregator},
		coreglib.TypeMarshaler{T: GTypeAggregatorPad, F: marshalAggregatorPad},
	})
}

// AggregatorOverrides contains methods that are overridable.
type AggregatorOverrides struct {
	// The function takes the following parameters:
	//
	// The function returns the following values:
	//
	Aggregate func(timeout bool) gst.FlowReturn
	// The function takes the following parameters:
	//
	//    - aggregatorPad
	//    - buf
	//
	// The function returns the following values:
	//
	Clip func(aggregatorPad *AggregatorPad, buf *gst.Buffer) *gst.Buffer
	// The function takes the following parameters:
	//
	// The function returns the following values:
	//
	DecideAllocation func(query *gst.Query) bool
	// FinishBuffer: this method will push the provided output buffer
	// downstream. If needed, mandatory events such as stream-start, caps, and
	// segment events will be sent before pushing the buffer.
	//
	// The function takes the following parameters:
	//
	//    - buffer to push.
	//
	// The function returns the following values:
	//
	FinishBuffer func(buffer *gst.Buffer) gst.FlowReturn
	// FinishBufferList: this method will push the provided output buffer list
	// downstream. If needed, mandatory events such as stream-start, caps, and
	// segment events will be sent before pushing the buffer.
	//
	// The function takes the following parameters:
	//
	//    - bufferlist to push.
	//
	// The function returns the following values:
	//
	FinishBufferList func(bufferlist *gst.BufferList) gst.FlowReturn
	// The function takes the following parameters:
	//
	// The function returns the following values:
	//
	FixateSrcCaps func(caps *gst.Caps) *gst.Caps
	// The function returns the following values:
	//
	Flush func() gst.FlowReturn
	// The function returns the following values:
	//
	NextTime func() gst.ClockTime
	// Negotiate negotiates src pad caps with downstream elements. Unmarks
	// GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it again if
	// AggregatorClass::negotiate fails.
	//
	// The function returns the following values:
	//
	//    - ok: TRUE if the negotiation succeeded, else FALSE.
	//
	Negotiate func() bool
	// The function takes the following parameters:
	//
	// The function returns the following values:
	//
	NegotiatedSrcCaps func(caps *gst.Caps) bool
	// PeekNextSample: use this function to determine what input buffers will be
	// aggregated to produce the next output buffer. This should only be called
	// from a Aggregator::samples-selected handler, and can be used to precisely
	// control aggregating parameters for a given set of input samples.
	//
	// The function takes the following parameters:
	//
	// The function returns the following values:
	//
	//    - sample (optional) that is about to be aggregated. It may hold a
	//      Buffer or a BufferList. The contents of its info structure is
	//      subclass-dependent, and documented on a subclass basis. The buffers
	//      held by the sample are not writable.
	//
	PeekNextSample func(aggregatorPad *AggregatorPad) *gst.Sample
	// The function takes the following parameters:
	//
	//    - pad
	//    - decideQuery
	//    - query
	//
	// The function returns the following values:
	//
	ProposeAllocation func(pad *AggregatorPad, decideQuery, query *gst.Query) bool
	// The function takes the following parameters:
	//
	//    - aggregatorPad
	//    - event
	//
	// The function returns the following values:
	//
	SinkEvent func(aggregatorPad *AggregatorPad, event *gst.Event) bool
	// The function takes the following parameters:
	//
	//    - aggregatorPad
	//    - event
	//
	// The function returns the following values:
	//
	SinkEventPreQueue func(aggregatorPad *AggregatorPad, event *gst.Event) gst.FlowReturn
	// The function takes the following parameters:
	//
	//    - aggregatorPad
	//    - query
	//
	// The function returns the following values:
	//
	SinkQuery func(aggregatorPad *AggregatorPad, query *gst.Query) bool
	// The function takes the following parameters:
	//
	//    - aggregatorPad
	//    - query
	//
	// The function returns the following values:
	//
	SinkQueryPreQueue func(aggregatorPad *AggregatorPad, query *gst.Query) bool
	// The function takes the following parameters:
	//
	//    - mode
	//    - active
	//
	// The function returns the following values:
	//
	SrcActivate func(mode gst.PadMode, active bool) bool
	// The function takes the following parameters:
	//
	// The function returns the following values:
	//
	SrcEvent func(event *gst.Event) bool
	// The function takes the following parameters:
	//
	// The function returns the following values:
	//
	SrcQuery func(query *gst.Query) bool
	// The function returns the following values:
	//
	Start func() bool
	// The function returns the following values:
	//
	Stop func() bool
	// The function takes the following parameters:
	//
	// The function returns the following values:
	//
	//    - ret (optional)
	//    - flowReturn
	//
	UpdateSrcCaps func(caps *gst.Caps) (*gst.Caps, gst.FlowReturn)
}

func defaultAggregatorOverrides(v *Aggregator) AggregatorOverrides {
	return AggregatorOverrides{
		Aggregate:         v.aggregate,
		Clip:              v.clip,
		DecideAllocation:  v.decideAllocation,
		FinishBuffer:      v.finishBuffer,
		FinishBufferList:  v.finishBufferList,
		FixateSrcCaps:     v.fixateSrcCaps,
		Flush:             v.flush,
		NextTime:          v.nextTime,
		Negotiate:         v.negotiate,
		NegotiatedSrcCaps: v.negotiatedSrcCaps,
		PeekNextSample:    v.peekNextSample,
		ProposeAllocation: v.proposeAllocation,
		SinkEvent:         v.sinkEvent,
		SinkEventPreQueue: v.sinkEventPreQueue,
		SinkQuery:         v.sinkQuery,
		SinkQueryPreQueue: v.sinkQueryPreQueue,
		SrcActivate:       v.srcActivate,
		SrcEvent:          v.srcEvent,
		SrcQuery:          v.srcQuery,
		Start:             v.start,
		Stop:              v.stop,
		UpdateSrcCaps:     v.updateSrcCaps,
	}
}

// Aggregator manages a set of pads with the purpose of aggregating their
// buffers. Control is given to the subclass when all pads have data.
//
//    * Base class for mixers and muxers. Subclasses should at least implement
//      the AggregatorClass::aggregate virtual method.
//
//    * Installs a PadChainFunction, a PadEventFullFunction and a
//      PadQueryFunction to queue all serialized data packets per sink pad.
//      Subclasses should not overwrite those, but instead implement
//      AggregatorClass::sink_event and AggregatorClass::sink_query as
//      needed.
//
//    * When data is queued on all pads, the aggregate vmethod is called.
//
//    * One can peek at the data on any given GstAggregatorPad with the
//      gst_aggregator_pad_peek_buffer() method, and remove it from the pad
//      with the gst_aggregator_pad_pop_buffer () method. When a buffer
//      has been taken with pop_buffer (), a new buffer can be queued
//      on that pad.
//
//    * When gst_aggregator_pad_peek_buffer() or gst_aggregator_pad_has_buffer()
//      are called, a reference is taken to the returned buffer, which stays
//      valid until either:
//
//        - gst_aggregator_pad_pop_buffer() is called, in which case the caller
//          is guaranteed that the buffer they receive is the same as the peeked
//          buffer.
//        - gst_aggregator_pad_drop_buffer() is called, in which case the caller
//          is guaranteed that the dropped buffer is the one that was peeked.
//        - the subclass implementation of AggregatorClass.aggregate returns.
//
//      Subsequent calls to gst_aggregator_pad_peek_buffer() or
//      gst_aggregator_pad_has_buffer() return / check the same buffer that was
//      returned / checked, until one of the conditions listed above is met.
//
//      Subclasses are only allowed to call these methods from the aggregate
//      thread.
//
//    * If the subclass wishes to push a buffer downstream in its aggregate
//      implementation, it should do so through the
//      gst_aggregator_finish_buffer() method. This method will take care
//      of sending and ordering mandatory events such as stream start, caps
//      and segment. Buffer lists can also be pushed out with
//      gst_aggregator_finish_buffer_list().
//
//    * Same goes for EOS events, which should not be pushed directly by the
//      subclass, it should instead return GST_FLOW_EOS in its aggregate
//      implementation.
//
//    * Note that the aggregator logic regarding gap event handling is to turn
//      these into gap buffers with matching PTS and duration. It will also
//      flag these buffers with GST_BUFFER_FLAG_GAP and GST_BUFFER_FLAG_DROPPABLE
//      to ease their identification and subsequent processing.
//
//    * Subclasses must use (a subclass of) AggregatorPad for both their
//      sink and source pads.
//      See gst_element_class_add_static_pad_template_with_gtype().
//
// This class used to live in gst-plugins-bad and was moved to core.
type Aggregator struct {
	_ [0]func() // equal guard
	gst.Element
}

var (
	_ gst.Elementer = (*Aggregator)(nil)
)

// Aggregatorrer describes types inherited from class Aggregator.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type Aggregatorrer interface {
	coreglib.Objector
	baseAggregator() *Aggregator
}

var _ Aggregatorrer = (*Aggregator)(nil)

func init() {
	coreglib.RegisterClassInfo[*Aggregator, *AggregatorClass, AggregatorOverrides](
		GTypeAggregator,
		initAggregatorClass,
		wrapAggregator,
		defaultAggregatorOverrides,
	)
}

func initAggregatorClass(gclass unsafe.Pointer, overrides AggregatorOverrides, classInitFunc func(*AggregatorClass)) {
	pclass := (*C.GstAggregatorClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAggregator))))

	if overrides.Aggregate != nil {
		pclass.aggregate = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_aggregate)
	}

	if overrides.Clip != nil {
		pclass.clip = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_clip)
	}

	if overrides.DecideAllocation != nil {
		pclass.decide_allocation = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_decide_allocation)
	}

	if overrides.FinishBuffer != nil {
		pclass.finish_buffer = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_finish_buffer)
	}

	if overrides.FinishBufferList != nil {
		pclass.finish_buffer_list = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_finish_buffer_list)
	}

	if overrides.FixateSrcCaps != nil {
		pclass.fixate_src_caps = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_fixate_src_caps)
	}

	if overrides.Flush != nil {
		pclass.flush = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_flush)
	}

	if overrides.NextTime != nil {
		pclass.get_next_time = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_get_next_time)
	}

	if overrides.Negotiate != nil {
		pclass.negotiate = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_negotiate)
	}

	if overrides.NegotiatedSrcCaps != nil {
		pclass.negotiated_src_caps = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_negotiated_src_caps)
	}

	if overrides.PeekNextSample != nil {
		pclass.peek_next_sample = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_peek_next_sample)
	}

	if overrides.ProposeAllocation != nil {
		pclass.propose_allocation = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_propose_allocation)
	}

	if overrides.SinkEvent != nil {
		pclass.sink_event = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_sink_event)
	}

	if overrides.SinkEventPreQueue != nil {
		pclass.sink_event_pre_queue = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_sink_event_pre_queue)
	}

	if overrides.SinkQuery != nil {
		pclass.sink_query = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_sink_query)
	}

	if overrides.SinkQueryPreQueue != nil {
		pclass.sink_query_pre_queue = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_sink_query_pre_queue)
	}

	if overrides.SrcActivate != nil {
		pclass.src_activate = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_src_activate)
	}

	if overrides.SrcEvent != nil {
		pclass.src_event = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_src_event)
	}

	if overrides.SrcQuery != nil {
		pclass.src_query = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_src_query)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_stop)
	}

	if overrides.UpdateSrcCaps != nil {
		pclass.update_src_caps = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_update_src_caps)
	}

	if classInitFunc != nil {
		class := (*AggregatorClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAggregator(obj *coreglib.Object) *Aggregator {
	return &Aggregator{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalAggregator(p uintptr) (interface{}, error) {
	return wrapAggregator(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (aggregator *Aggregator) baseAggregator() *Aggregator {
	return aggregator
}

// BaseAggregator returns the underlying base object.
func BaseAggregator(obj Aggregatorrer) *Aggregator {
	return obj.baseAggregator()
}

// ConnectSamplesSelected signals that the Aggregator subclass has selected the
// next set of input samples it will aggregate. Handlers may call
// gst_aggregator_peek_next_sample() at that point.
func (aggregator *Aggregator) ConnectSamplesSelected(f func(segment *gst.Segment, pts, dts, duration uint64, info *gst.Structure)) coreglib.SignalHandle {
	return coreglib.ConnectGeneratedClosure(aggregator, "samples-selected", false, unsafe.Pointer(C._gotk4_gstbase1_Aggregator_ConnectSamplesSelected), f)
}

// FinishBuffer: this method will push the provided output buffer downstream. If
// needed, mandatory events such as stream-start, caps, and segment events will
// be sent before pushing the buffer.
//
// The function takes the following parameters:
//
//    - buffer to push.
//
// The function returns the following values:
//
func (aggregator *Aggregator) FinishBuffer(buffer *gst.Buffer) gst.FlowReturn {
	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstBuffer     // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buffer)), nil)

	_cret = C.gst_aggregator_finish_buffer(_arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// FinishBufferList: this method will push the provided output buffer list
// downstream. If needed, mandatory events such as stream-start, caps, and
// segment events will be sent before pushing the buffer.
//
// The function takes the following parameters:
//
//    - bufferlist to push.
//
// The function returns the following values:
//
func (aggregator *Aggregator) FinishBufferList(bufferlist *gst.BufferList) gst.FlowReturn {
	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstBufferList // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstBufferList)(gextras.StructNative(unsafe.Pointer(bufferlist)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(bufferlist)), nil)

	_cret = C.gst_aggregator_finish_buffer_list(_arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(bufferlist)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Allocator lets Aggregator sub-classes get the memory allocator acquired by
// the base class and its params.
//
// Unref the allocator after use it.
//
// The function returns the following values:
//
//    - allocator (optional): Allocator used.
//    - params (optional) the AllocationParams of allocator.
//
func (self *Aggregator) Allocator() (gst.Allocatorrer, *gst.AllocationParams) {
	var _arg0 *C.GstAggregator      // out
	var _arg1 *C.GstAllocator       // in
	var _arg2 C.GstAllocationParams // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))

	C.gst_aggregator_get_allocator(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(self)

	var _allocator gst.Allocatorrer   // out
	var _params *gst.AllocationParams // out

	if _arg1 != nil {
		{
			objptr := unsafe.Pointer(_arg1)

			object := coreglib.AssumeOwnership(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(gst.Allocatorrer)
				return ok
			})
			rv, ok := casted.(gst.Allocatorrer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gst.Allocatorrer")
			}
			_allocator = rv
		}
	}
	_params = (*gst.AllocationParams)(gextras.NewStructNative(unsafe.Pointer((&_arg2))))

	return _allocator, _params
}

// The function returns the following values:
//
//    - bufferPool (optional): instance of the BufferPool used by trans; free it
//      after use it.
//
func (self *Aggregator) BufferPool() *gst.BufferPool {
	var _arg0 *C.GstAggregator // out
	var _cret *C.GstBufferPool // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))

	_cret = C.gst_aggregator_get_buffer_pool(_arg0)
	runtime.KeepAlive(self)

	var _bufferPool *gst.BufferPool // out

	if _cret != nil {
		{
			obj := coreglib.AssumeOwnership(unsafe.Pointer(_cret))
			_bufferPool = &gst.BufferPool{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			}
		}
	}

	return _bufferPool
}

// The function returns the following values:
//
//    - ok: whether inactive pads will not be waited on.
//
func (self *Aggregator) IgnoreInactivePads() bool {
	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))

	_cret = C.gst_aggregator_get_ignore_inactive_pads(_arg0)
	runtime.KeepAlive(self)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Latency retrieves the latency values reported by self in response to the
// latency query, or GST_CLOCK_TIME_NONE if there is not live source connected
// and the element will not wait for the clock.
//
// Typically only called by subclasses.
//
// The function returns the following values:
//
//    - clockTime: latency or GST_CLOCK_TIME_NONE if the element does not sync.
//
func (self *Aggregator) Latency() gst.ClockTime {
	var _arg0 *C.GstAggregator // out
	var _cret C.GstClockTime   // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))

	_cret = C.gst_aggregator_get_latency(_arg0)
	runtime.KeepAlive(self)

	var _clockTime gst.ClockTime // out

	_clockTime = uint64(_cret)
	type _ = gst.ClockTime
	type _ = uint64

	return _clockTime
}

// Negotiate negotiates src pad caps with downstream elements. Unmarks
// GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it again if
// AggregatorClass::negotiate fails.
//
// The function returns the following values:
//
//    - ok: TRUE if the negotiation succeeded, else FALSE.
//
func (self *Aggregator) Negotiate() bool {
	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))

	_cret = C.gst_aggregator_negotiate(_arg0)
	runtime.KeepAlive(self)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PeekNextSample: use this function to determine what input buffers will be
// aggregated to produce the next output buffer. This should only be called from
// a Aggregator::samples-selected handler, and can be used to precisely control
// aggregating parameters for a given set of input samples.
//
// The function takes the following parameters:
//
// The function returns the following values:
//
//    - sample (optional) that is about to be aggregated. It may hold a Buffer or
//      a BufferList. The contents of its info structure is subclass-dependent,
//      and documented on a subclass basis. The buffers held by the sample are
//      not writable.
//
func (self *Aggregator) PeekNextSample(pad *AggregatorPad) *gst.Sample {
	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _cret *C.GstSample        // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(pad).Native()))

	_cret = C.gst_aggregator_peek_next_sample(_arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(pad)

	var _sample *gst.Sample // out

	if _cret != nil {
		_sample = (*gst.Sample)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_sample)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.free(intern.C)
			},
		)
	}

	return _sample
}

// SelectedSamples subclasses should call this when they have prepared the
// buffers they will aggregate for each of their sink pads, but before using any
// of the properties of the pads that govern *how* aggregation should be
// performed, for example z-index for video aggregators.
//
// If gst_aggregator_update_segment() is used by the subclass, it MUST be called
// before gst_aggregator_selected_samples().
//
// This function MUST only be called from the AggregatorClass::aggregate()
// function.
//
// The function takes the following parameters:
//
//    - pts: presentation timestamp of the next output buffer.
//    - dts: decoding timestamp of the next output buffer.
//    - duration of the next output buffer.
//    - info (optional) containing additional information.
//
func (self *Aggregator) SelectedSamples(pts, dts, duration gst.ClockTime, info *gst.Structure) {
	var _arg0 *C.GstAggregator // out
	var _arg1 C.GstClockTime   // out
	var _arg2 C.GstClockTime   // out
	var _arg3 C.GstClockTime   // out
	var _arg4 *C.GstStructure  // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = C.guint64(pts)
	type _ = gst.ClockTime
	type _ = uint64
	_arg2 = C.guint64(dts)
	type _ = gst.ClockTime
	type _ = uint64
	_arg3 = C.guint64(duration)
	type _ = gst.ClockTime
	type _ = uint64
	if info != nil {
		_arg4 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(info)))
	}

	C.gst_aggregator_selected_samples(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(self)
	runtime.KeepAlive(pts)
	runtime.KeepAlive(dts)
	runtime.KeepAlive(duration)
	runtime.KeepAlive(info)
}

// SetIgnoreInactivePads subclasses should call this when they don't want to
// time out waiting for a pad that hasn't yet received any buffers in live mode.
//
// Aggregator will still wait once on each newly-added pad, making sure upstream
// has had a fair chance to start up.
//
// The function takes the following parameters:
//
//    - ignore: whether inactive pads should not be waited on.
//
func (self *Aggregator) SetIgnoreInactivePads(ignore bool) {
	var _arg0 *C.GstAggregator // out
	var _arg1 C.gboolean       // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	if ignore {
		_arg1 = C.TRUE
	}

	C.gst_aggregator_set_ignore_inactive_pads(_arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(ignore)
}

// SetLatency lets Aggregator sub-classes tell the baseclass what their internal
// latency is. Will also post a LATENCY message on the bus so the pipeline can
// reconfigure its global latency.
//
// The function takes the following parameters:
//
//    - minLatency: minimum latency.
//    - maxLatency: maximum latency.
//
func (self *Aggregator) SetLatency(minLatency, maxLatency gst.ClockTime) {
	var _arg0 *C.GstAggregator // out
	var _arg1 C.GstClockTime   // out
	var _arg2 C.GstClockTime   // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = C.guint64(minLatency)
	type _ = gst.ClockTime
	type _ = uint64
	_arg2 = C.guint64(maxLatency)
	type _ = gst.ClockTime
	type _ = uint64

	C.gst_aggregator_set_latency(_arg0, _arg1, _arg2)
	runtime.KeepAlive(self)
	runtime.KeepAlive(minLatency)
	runtime.KeepAlive(maxLatency)
}

// SetSrcCaps sets the caps to be used on the src pad.
//
// The function takes the following parameters:
//
//    - caps to set on the src pad.
//
func (self *Aggregator) SetSrcCaps(caps *gst.Caps) {
	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstCaps       // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	C.gst_aggregator_set_src_caps(_arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(caps)
}

// SimpleGetNextTime: this is a simple AggregatorClass::get_next_time
// implementation that just looks at the Segment on the srcpad of the aggregator
// and bases the next time on the running time there.
//
// This is the desired behaviour in most cases where you have a live source and
// you have a dead line based aggregator subclass.
//
// The function returns the following values:
//
//    - clockTime: running time based on the position.
//
func (self *Aggregator) SimpleGetNextTime() gst.ClockTime {
	var _arg0 *C.GstAggregator // out
	var _cret C.GstClockTime   // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))

	_cret = C.gst_aggregator_simple_get_next_time(_arg0)
	runtime.KeepAlive(self)

	var _clockTime gst.ClockTime // out

	_clockTime = uint64(_cret)
	type _ = gst.ClockTime
	type _ = uint64

	return _clockTime
}

// UpdateSegment subclasses should use this to update the segment on their
// source pad, instead of directly pushing new segment events downstream.
//
// Subclasses MUST call this before gst_aggregator_selected_samples(), if it is
// used at all.
//
// The function takes the following parameters:
//
func (self *Aggregator) UpdateSegment(segment *gst.Segment) {
	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstSegment    // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = (*C.GstSegment)(gextras.StructNative(unsafe.Pointer(segment)))

	C.gst_aggregator_update_segment(_arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(segment)
}

// The function takes the following parameters:
//
// The function returns the following values:
//
func (aggregator *Aggregator) aggregate(timeout bool) gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.aggregate

	var _arg0 *C.GstAggregator // out
	var _arg1 C.gboolean       // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	if timeout {
		_arg1 = C.TRUE
	}

	_cret = C._gotk4_gstbase1_Aggregator_virtual_aggregate(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(timeout)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// The function takes the following parameters:
//
//    - aggregatorPad
//    - buf
//
// The function returns the following values:
//
func (aggregator *Aggregator) clip(aggregatorPad *AggregatorPad, buf *gst.Buffer) *gst.Buffer {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.clip

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstBuffer        // out
	var _cret *C.GstBuffer        // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(aggregatorPad).Native()))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_clip(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(buf)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _buffer
}

// The function takes the following parameters:
//
// The function returns the following values:
//
func (self *Aggregator) decideAllocation(query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.decide_allocation

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstQuery      // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_decide_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// finishBuffer: this method will push the provided output buffer downstream. If
// needed, mandatory events such as stream-start, caps, and segment events will
// be sent before pushing the buffer.
//
// The function takes the following parameters:
//
//    - buffer to push.
//
// The function returns the following values:
//
func (aggregator *Aggregator) finishBuffer(buffer *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.finish_buffer

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstBuffer     // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buffer)), nil)

	_cret = C._gotk4_gstbase1_Aggregator_virtual_finish_buffer(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// finishBufferList: this method will push the provided output buffer list
// downstream. If needed, mandatory events such as stream-start, caps, and
// segment events will be sent before pushing the buffer.
//
// The function takes the following parameters:
//
//    - bufferlist to push.
//
// The function returns the following values:
//
func (aggregator *Aggregator) finishBufferList(bufferlist *gst.BufferList) gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.finish_buffer_list

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstBufferList // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstBufferList)(gextras.StructNative(unsafe.Pointer(bufferlist)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(bufferlist)), nil)

	_cret = C._gotk4_gstbase1_Aggregator_virtual_finish_buffer_list(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(bufferlist)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// The function takes the following parameters:
//
// The function returns the following values:
//
func (self *Aggregator) fixateSrcCaps(caps *gst.Caps) *gst.Caps {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.fixate_src_caps

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstCaps       // out
	var _cret *C.GstCaps       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_fixate_src_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(caps)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _ret
}

// The function returns the following values:
//
func (aggregator *Aggregator) flush() gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.flush

	var _arg0 *C.GstAggregator // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_flush(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(aggregator)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// The function returns the following values:
//
func (aggregator *Aggregator) nextTime() gst.ClockTime {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.get_next_time

	var _arg0 *C.GstAggregator // out
	var _cret C.GstClockTime   // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_get_next_time(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(aggregator)

	var _clockTime gst.ClockTime // out

	_clockTime = uint64(_cret)
	type _ = gst.ClockTime
	type _ = uint64

	return _clockTime
}

// Negotiate negotiates src pad caps with downstream elements. Unmarks
// GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it again if
// AggregatorClass::negotiate fails.
//
// The function returns the following values:
//
//    - ok: TRUE if the negotiation succeeded, else FALSE.
//
func (self *Aggregator) negotiate() bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.negotiate

	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_negotiate(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(self)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
// The function returns the following values:
//
func (self *Aggregator) negotiatedSrcCaps(caps *gst.Caps) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.negotiated_src_caps

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstCaps       // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_negotiated_src_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// peekNextSample: use this function to determine what input buffers will be
// aggregated to produce the next output buffer. This should only be called from
// a Aggregator::samples-selected handler, and can be used to precisely control
// aggregating parameters for a given set of input samples.
//
// The function takes the following parameters:
//
// The function returns the following values:
//
//    - sample (optional) that is about to be aggregated. It may hold a Buffer or
//      a BufferList. The contents of its info structure is subclass-dependent,
//      and documented on a subclass basis. The buffers held by the sample are
//      not writable.
//
func (aggregator *Aggregator) peekNextSample(aggregatorPad *AggregatorPad) *gst.Sample {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.peek_next_sample

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _cret *C.GstSample        // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(aggregatorPad).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_peek_next_sample(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)

	var _sample *gst.Sample // out

	if _cret != nil {
		_sample = (*gst.Sample)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_sample)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.free(intern.C)
			},
		)
	}

	return _sample
}

// The function takes the following parameters:
//
//    - pad
//    - decideQuery
//    - query
//
// The function returns the following values:
//
func (self *Aggregator) proposeAllocation(pad *AggregatorPad, decideQuery, query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.propose_allocation

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstQuery         // out
	var _arg3 *C.GstQuery         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(pad).Native()))
	_arg2 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(decideQuery)))
	_arg3 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_propose_allocation(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(self)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(decideQuery)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
//    - aggregatorPad
//    - event
//
// The function returns the following values:
//
func (aggregator *Aggregator) sinkEvent(aggregatorPad *AggregatorPad, event *gst.Event) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.sink_event

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstEvent         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(aggregatorPad).Native()))
	_arg2 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_sink_event(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
//    - aggregatorPad
//    - event
//
// The function returns the following values:
//
func (aggregator *Aggregator) sinkEventPreQueue(aggregatorPad *AggregatorPad, event *gst.Event) gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.sink_event_pre_queue

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstEvent         // out
	var _cret C.GstFlowReturn     // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(aggregatorPad).Native()))
	_arg2 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_sink_event_pre_queue(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(event)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// The function takes the following parameters:
//
//    - aggregatorPad
//    - query
//
// The function returns the following values:
//
func (aggregator *Aggregator) sinkQuery(aggregatorPad *AggregatorPad, query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.sink_query

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstQuery         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(aggregatorPad).Native()))
	_arg2 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_sink_query(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
//    - aggregatorPad
//    - query
//
// The function returns the following values:
//
func (aggregator *Aggregator) sinkQueryPreQueue(aggregatorPad *AggregatorPad, query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.sink_query_pre_queue

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstQuery         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(aggregatorPad).Native()))
	_arg2 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_sink_query_pre_queue(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
//    - mode
//    - active
//
// The function returns the following values:
//
func (aggregator *Aggregator) srcActivate(mode gst.PadMode, active bool) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.src_activate

	var _arg0 *C.GstAggregator // out
	var _arg1 C.GstPadMode     // out
	var _arg2 C.gboolean       // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = C.GstPadMode(mode)
	if active {
		_arg2 = C.TRUE
	}

	_cret = C._gotk4_gstbase1_Aggregator_virtual_src_activate(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(mode)
	runtime.KeepAlive(active)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
// The function returns the following values:
//
func (aggregator *Aggregator) srcEvent(event *gst.Event) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.src_event

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstEvent      // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_src_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
// The function returns the following values:
//
func (aggregator *Aggregator) srcQuery(query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.src_query

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstQuery      // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_src_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
func (aggregator *Aggregator) start() bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.start

	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(aggregator)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
func (aggregator *Aggregator) stop() bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.stop

	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(aggregator)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
// The function returns the following values:
//
//    - ret (optional)
//    - flowReturn
//
func (self *Aggregator) updateSrcCaps(caps *gst.Caps) (*gst.Caps, gst.FlowReturn) {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.update_src_caps

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstCaps       // out
	var _arg2 *C.GstCaps       // in
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(self).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_update_src_caps(unsafe.Pointer(fnarg), _arg0, _arg1, &_arg2)
	runtime.KeepAlive(self)
	runtime.KeepAlive(caps)

	var _ret *gst.Caps             // out
	var _flowReturn gst.FlowReturn // out

	if _arg2 != nil {
		_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_arg2)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_ret)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.free(intern.C)
			},
		)
	}
	_flowReturn = gst.FlowReturn(_cret)

	return _ret, _flowReturn
}

// AggregatorPadOverrides contains methods that are overridable.
type AggregatorPadOverrides struct {
	// The function takes the following parameters:
	//
	// The function returns the following values:
	//
	Flush func(aggregator Aggregatorrer) gst.FlowReturn
	// The function takes the following parameters:
	//
	//    - aggregator
	//    - buffer
	//
	// The function returns the following values:
	//
	SkipBuffer func(aggregator Aggregatorrer, buffer *gst.Buffer) bool
}

func defaultAggregatorPadOverrides(v *AggregatorPad) AggregatorPadOverrides {
	return AggregatorPadOverrides{
		Flush:      v.flush,
		SkipBuffer: v.skipBuffer,
	}
}

// AggregatorPad pads managed by a Aggregator subclass.
//
// This class used to live in gst-plugins-bad and was moved to core.
type AggregatorPad struct {
	_ [0]func() // equal guard
	gst.Pad
}

var (
	_ gst.GstObjector = (*AggregatorPad)(nil)
)

func init() {
	coreglib.RegisterClassInfo[*AggregatorPad, *AggregatorPadClass, AggregatorPadOverrides](
		GTypeAggregatorPad,
		initAggregatorPadClass,
		wrapAggregatorPad,
		defaultAggregatorPadOverrides,
	)
}

func initAggregatorPadClass(gclass unsafe.Pointer, overrides AggregatorPadOverrides, classInitFunc func(*AggregatorPadClass)) {
	pclass := (*C.GstAggregatorPadClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAggregatorPad))))

	if overrides.Flush != nil {
		pclass.flush = (*[0]byte)(C._gotk4_gstbase1_AggregatorPadClass_flush)
	}

	if overrides.SkipBuffer != nil {
		pclass.skip_buffer = (*[0]byte)(C._gotk4_gstbase1_AggregatorPadClass_skip_buffer)
	}

	if classInitFunc != nil {
		class := (*AggregatorPadClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAggregatorPad(obj *coreglib.Object) *AggregatorPad {
	return &AggregatorPad{
		Pad: gst.Pad{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalAggregatorPad(p uintptr) (interface{}, error) {
	return wrapAggregatorPad(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (pad *AggregatorPad) ConnectBufferConsumed(f func(object *gst.Buffer)) coreglib.SignalHandle {
	return coreglib.ConnectGeneratedClosure(pad, "buffer-consumed", false, unsafe.Pointer(C._gotk4_gstbase1_AggregatorPad_ConnectBufferConsumed), f)
}

// DropBuffer: drop the buffer currently queued in pad.
//
// The function returns the following values:
//
//    - ok: TRUE if there was a buffer queued in pad, or FALSE if not.
//
func (pad *AggregatorPad) DropBuffer() bool {
	var _arg0 *C.GstAggregatorPad // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(pad).Native()))

	_cret = C.gst_aggregator_pad_drop_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// HasBuffer: this checks if a pad has a buffer available that will be returned
// by a call to gst_aggregator_pad_peek_buffer() or
// gst_aggregator_pad_pop_buffer().
//
// The function returns the following values:
//
//    - ok: TRUE if the pad has a buffer available as the next thing.
//
func (pad *AggregatorPad) HasBuffer() bool {
	var _arg0 *C.GstAggregatorPad // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(pad).Native()))

	_cret = C.gst_aggregator_pad_has_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//    - ok: TRUE if the pad is EOS, otherwise FALSE.
//
func (pad *AggregatorPad) IsEos() bool {
	var _arg0 *C.GstAggregatorPad // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(pad).Native()))

	_cret = C.gst_aggregator_pad_is_eos(_arg0)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsInactive: it is only valid to call this method from
// AggregatorClass::aggregate().
//
// The function returns the following values:
//
//    - ok: TRUE if the pad is inactive, FALSE otherwise. See
//      gst_aggregator_ignore_inactive_pads() for more info.
//
func (pad *AggregatorPad) IsInactive() bool {
	var _arg0 *C.GstAggregatorPad // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(pad).Native()))

	_cret = C.gst_aggregator_pad_is_inactive(_arg0)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//    - buffer (optional): reference to the buffer in pad or NULL if no buffer
//      was queued. You should unref the buffer after usage.
//
func (pad *AggregatorPad) PeekBuffer() *gst.Buffer {
	var _arg0 *C.GstAggregatorPad // out
	var _cret *C.GstBuffer        // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(pad).Native()))

	_cret = C.gst_aggregator_pad_peek_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.free(intern.C)
			},
		)
	}

	return _buffer
}

// PopBuffer: steal the ref to the buffer currently queued in pad.
//
// The function returns the following values:
//
//    - buffer (optional) in pad or NULL if no buffer was queued. You should
//      unref the buffer after usage.
//
func (pad *AggregatorPad) PopBuffer() *gst.Buffer {
	var _arg0 *C.GstAggregatorPad // out
	var _cret *C.GstBuffer        // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(pad).Native()))

	_cret = C.gst_aggregator_pad_pop_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.free(intern.C)
			},
		)
	}

	return _buffer
}

// The function takes the following parameters:
//
// The function returns the following values:
//
func (aggpad *AggregatorPad) flush(aggregator Aggregatorrer) gst.FlowReturn {
	gclass := (*C.GstAggregatorPadClass)(coreglib.PeekParentClass(aggpad))
	fnarg := gclass.flush

	var _arg0 *C.GstAggregatorPad // out
	var _arg1 *C.GstAggregator    // out
	var _cret C.GstFlowReturn     // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(aggpad).Native()))
	_arg1 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_AggregatorPad_virtual_flush(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggpad)
	runtime.KeepAlive(aggregator)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// The function takes the following parameters:
//
//    - aggregator
//    - buffer
//
// The function returns the following values:
//
func (aggpad *AggregatorPad) skipBuffer(aggregator Aggregatorrer, buffer *gst.Buffer) bool {
	gclass := (*C.GstAggregatorPadClass)(coreglib.PeekParentClass(aggpad))
	fnarg := gclass.skip_buffer

	var _arg0 *C.GstAggregatorPad // out
	var _arg1 *C.GstAggregator    // out
	var _arg2 *C.GstBuffer        // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.InternObject(aggpad).Native()))
	_arg1 = (*C.GstAggregator)(unsafe.Pointer(coreglib.InternObject(aggregator).Native()))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstbase1_AggregatorPad_virtual_skip_buffer(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggpad)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(buffer)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AggregatorClass: aggregator base class will handle in a thread-safe way all
// manners of concurrent flushes, seeks, pad additions and removals, leaving to
// the subclass the responsibility of clipping buffers, and aggregating buffers
// in the way the implementor sees fit.
//
// It will also take care of event ordering (stream-start, segment, eos).
//
// Basically, a simple implementation will override aggregate, and call
// _finish_buffer from inside that function.
//
// An instance of this type is always passed by reference.
type AggregatorClass struct {
	*aggregatorClass
}

// aggregatorClass is the struct that's finalized.
type aggregatorClass struct {
	native *C.GstAggregatorClass
}

func (a *AggregatorClass) ParentClass() *gst.ElementClass {
	valptr := &a.native.parent_class
	var _v *gst.ElementClass // out
	_v = (*gst.ElementClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AggregatorPadClass: instance of this type is always passed by reference.
type AggregatorPadClass struct {
	*aggregatorPadClass
}

// aggregatorPadClass is the struct that's finalized.
type aggregatorPadClass struct {
	native *C.GstAggregatorPadClass
}

func (a *AggregatorPadClass) ParentClass() *gst.PadClass {
	valptr := &a.native.parent_class
	var _v *gst.PadClass // out
	_v = (*gst.PadClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}
